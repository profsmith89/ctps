

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 18: Use Generative AI &#8212; Computational Thinking and Problem Solving</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chap18';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Active-Learning Exercises" href="ales.html" />
    <link rel="prev" title="Chapter 17: Build Prediction Models" href="chap17.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="ctps.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/mike_flat.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/mike_flat.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="ctps.html">
                    <no title>
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="welcome.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap01.html">Chapter 1: Read a Children’s Book</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap02.html">Chapter 2: Grab the Dialogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap03.html">Chapter 3: Replace Text With Emoji</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap04.html">Chapter 4: Query a Web Resource</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap05.html">Chapter 5: Play Guess-a-number</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap06.html">Chapter 6: Do You See My Dog?</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap07.html">Chapter 7: Many But Not Any Number</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap08.html">Chapter 8: What Is My Problem?</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap09.html">Chapter 9: Find a Phrase</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap10.html">Chapter 10: Build an Index</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap11.html">Chapter 11: Discover Driving Directions</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap12.html">Chapter 12: Divide and Conquer</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap13.html">Chapter 13: Rewrite the Error Message</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap14.html">Chapter 14: The Dream of Bug Fixing</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap15.html">Chapter 15: Embrace Runtime Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap16.html">Chapter 16: Catch Them Early</a></li>
<li class="toctree-l1"><a class="reference internal" href="chap17.html">Chapter 17: Build Prediction Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Chapter 18: Use Generative AI</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ales.html">Active-Learning Exercises</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="ales-c01.html">Chapter 1</a></li>





<li class="toctree-l2"><a class="reference internal" href="ales-c02.html">Chapter 2</a></li>







<li class="toctree-l2"><a class="reference internal" href="ales-c03.html">Chapter 3</a></li>










<li class="toctree-l2"><a class="reference internal" href="ales-c04.html">Chapter 4</a></li>





<li class="toctree-l2"><a class="reference internal" href="ales-c05.html">Chapter 5</a></li>
<li class="toctree-l2"><a class="reference internal" href="ales-c06.html">Chapter 6</a></li>
<li class="toctree-l2"><a class="reference internal" href="ales-c07.html">Chapter 7</a></li>
<li class="toctree-l2"><a class="reference internal" href="ales-c08.html">Chapter 8</a></li>
<li class="toctree-l2"><a class="reference internal" href="ales-c09.html">Chapter 9</a></li>



<li class="toctree-l2"><a class="reference internal" href="ales-c10.html">Chapter 10</a></li>
<li class="toctree-l2"><a class="reference internal" href="ales-c11.html">Chapter 11</a></li>
<li class="toctree-l2"><a class="reference internal" href="ales-c12.html">Chapter 12</a></li>



</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/chap18.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 18: Use Generative AI</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#navigating-the-jagged-frontier">Navigating the jagged frontier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#my-use-of-gai">My use of GAI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-llms">Large Language Models (LLMs)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-operation-of-llms">The operation of LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity-from-simplicity">Complexity from simplicity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-neural-network">Training a neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-pieces-to-problem-solving-with-gai">Two pieces to problem solving with GAI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-easy-request">An easy request?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-the-script-ourselves">Write the script ourselves</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ask-chatgpt">Ask ChatGPT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-this-task-within-the-frontier">Is this task within the frontier?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-expanding-frontier">The expanding frontier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-problem-solve-with-a-llm">How to problem solve with a LLM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#writing-good-prompts">Writing good prompts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-thoughts">Final thoughts</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-18-use-generative-ai">
<h1>Chapter 18: Use Generative AI<a class="headerlink" href="#chapter-18-use-generative-ai" title="Permalink to this heading">#</a></h1>
<p>You’ve reached this book’s end, and we have one last problem to solve: how should you use the skills and knowledge you’ve gained in a world where generative artificial intelligence (GAI) can turn a short English description of a problem into working Python code? GAI is a computational tool you prompt to generate new content. It is (mostly) a predictive model that has been trained on a huge corpus of (typically) real-world data to be good at a particular task, like generating human-sounding text, Python code, images, or short videos.</p>
<p>Here’s an example using OpenAI’s ChatGPT (GPT-4):</p>
<blockquote>
<div><p><strong>Me:</strong> Write a python script that prints a text file so that each line starts with a line number.</p>
<p><strong>ChatGPT:</strong> Certainly! Here’s a Python script that reads a text file and prints each line prefixed with its line number. I’ll include some comments in the script to explain each step.</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1">### chap18/num_lines.py -- Written by ChatGPT</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="k">def</span> <span class="nf">print_numbered_lines</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
<span class="linenos"> 4</span>    <span class="k">try</span><span class="p">:</span>
<span class="linenos"> 5</span>        <span class="c1"># Open the file in read mode</span>
<span class="linenos"> 6</span>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
<span class="linenos"> 7</span>            <span class="c1"># Read all lines in the file</span>
<span class="linenos"> 8</span>            <span class="n">lines</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="linenos"> 9</span>        
<span class="linenos">10</span>        <span class="c1"># Loop through the lines, enumerate starts counting from 0 by default</span>
<span class="linenos">11</span>        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="linenos">12</span>            <span class="c1"># Print each line with its line number</span>
<span class="linenos">13</span>            <span class="c1"># Strip is used to remove any extra newline characters before adding our own</span>
<span class="linenos">14</span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos">15</span>    
<span class="linenos">16</span>    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
<span class="linenos">17</span>        <span class="c1"># If the file is not found, inform the user</span>
<span class="linenos">18</span>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The file was not found. Please check the file path and try again.&quot;</span><span class="p">)</span>
<span class="linenos">19</span>
<span class="linenos">20</span><span class="c1"># You can call the function with the path to the file you want to print</span>
<span class="linenos">21</span><span class="c1"># For example: print_numbered_lines(&quot;example.txt&quot;)</span>
</pre></div>
</div>
<p>If you’re using this book in a course that has adopted my programming problem sets, you’ll recognize this prompt as Part 1 of your first programming assignment. While the code above is almost certainly not what you wrote then—it uses programming constructs and Python functions that we didn’t cover until later chapters—and not what you might write now—the try-exception statement provides less information than the Python interpreter’s default error message—you’ll see that this function works.</p>
<p>Are your new skills worthless? No!</p>
<p>As this book’s author, my emphatic no might not surprise you, but let me explain. At the start of Act I, you probably found this prompt to be a challenging task, but here at the end of Act III, you know that it isn’t. I ask my students to tackle this challenge because it helps them learn:</p>
<ol class="arabic simple">
<li><p>the basics of worklist processing, which is a widely applicable technique used in computational thinking and problem solving more generally;</p></li>
<li><p>to read and write several widely-used statements in Python syntax; and</p></li>
<li><p>to recognize and fix flaws in a Python script.</p></li>
</ol>
<p>You’ve learned these lessons, and you now can write this code as easily as you do basic math. And despite <em>knowing</em> how to do basic math, we don’t always <em>choose</em> to do it. Sometimes we rely on a calculator or a spreadsheet. While GAI tools don’t operate, as we’ll soon discuss, like calculators or spreadsheet programs, they’re useful when <em>getting to an answer quickly is more important than doing the work ourselves</em>. The same rule applies to GAI tools.</p>
<p>Act III has been all about tools, like GAI, that enable us to more quickly solve problems. In particular, it has covered two types of tools. Ones that help us to:</p>
<ul class="simple">
<li><p><em>understand why</em> a script failed (e.g., a debugger); and</p></li>
<li><p><em>do less</em> in Steps 5-7 of Chapter 1’s problem-solving process (e.g., ML libraries).</p></li>
</ul>
<p>GAI tools assist in both ways. They don’t change the eight steps in our problem-solving process or eliminate the need to iterate when a script fails, whether one we wrote or a GAI produced, but GAI tools can pinpoint where in the problem-solving process we need to return and allow us to focus on the larger tasks involved in problem solving.</p>
<div class="admonition-learning-outcomes admonition">
<p class="admonition-title">Learning Outcomes</p>
<p>Learn to use generative artificial intelligence (GAI), and large language models (LLMs) in particular, as tools for problem solving. You will discover that GAI tools don’t fundamentally change the problem-solving process we discussed in Chapter 1. You’ll gain an understanding how these tools operate and how they’re not like calculators and spreadsheets. You’ll learn how to use them so that you become a more productive problem solver. After completing this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Explain GAI in layman’s terms [CS concepts];</p></li>
<li><p>Use a simple framework to think precisely about how you’d like to employ a GAI tool [design];</p></li>
<li><p>Describe the general operation and training of a LLM [CS concepts];</p></li>
<li><p>Determine whether the problem-solving task you’ve assigned a LLM is within its capabilities, and when it is not, adjust your approach to get some benefit from the tool [design and programming skills];</p></li>
<li><p>Structure the prompts you give to a LLM through prompt engineering so that it’s more likely to successfully accomplish your requested task [programming skills];</p></li>
<li><p>Understand why “programming” in English (or any human language) is a two-edged sword [CS concepts].</p></li>
</ul>
</div>
<section id="navigating-the-jagged-frontier">
<p><strong>Navigating the jagged frontier.</strong> While GAIs are tools that can augment your newly attained abilities, there are (at least) two gotchas. I’ll describe the first now as further justification for my earlier emphatic no and the second later after we talk about how a particular type of GAI used in writing code, the Large Language Model (LLM), works.</p>
<p>The first is nicely illustrated by a 2023 study from Harvard Business School researchers<a class="footnote-reference brackets" href="#fn1" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> who investigated how the productivity and work-product quality of knowledge workers changed when using a GAI tool. In their study, there were three sets of consultants:</p>
<ul class="simple">
<li><p>those who were not allowed to use a GAI tool;</p></li>
<li><p>those who were allowed to use a GAI tool; and</p></li>
<li><p>those who were allowed to use a GAI tool and were told what makes a good prompt.</p></li>
</ul>
<p>The study’s authors devised a set of tasks for these consultants to solve that were both within and beyond the capabilities of the GAI tool. The limit of the GAI’s abilities is what the researchers called its <em>frontier</em>. Like any person’s knowledge and skills, this frontier is jagged, meaning that given a large number of tasks with the same perceived difficulty the GAI tool will complete some of these tasks better than others. Or stated another way, for a task within the frontier, the GAI tool’s responses will be largely correct and helpful. But for a task outside it, the GAI tool’s responses will be largely incorrect, although the flaws in its responses may not be immediately obvious.</p>
<figure class="align-default" id="c18-fig1-ref">
<img alt="_images/c18_fig1.png" src="_images/c18_fig1.png" />
<figcaption>
<p><span class="caption-number">Fig. 36 </span><span class="caption-text">An illustration of the jagged frontier of any GAI tool’s capabilities, from Dell’Acqua et al. [2023].</span><a class="headerlink" href="#c18-fig1-ref" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This study’s findings tell an important story about how we should use GAI tools in our own work. On tasks <em>within</em> the frontier (i.e., where the GAI tool worked well), the authors found:</p>
<ul class="simple">
<li><p>Consultants using a GAI tool were “significantly more productive (they completed 12.2% <em>more tasks</em> on average, and completed tasks 25.1% <em>more quickly</em>), and produced significantly <em>higher quality results</em> (more than 40% higher quality …).” [Emphasis added.]</p></li>
<li><p>Plus, those <em>individuals with below-average skills benefited more</em> from using a GAI tool (a 43% boost versus 17%). [Emphasis added.]</p></li>
</ul>
<p>Perhaps unsurprising, when a tool is appropriate for the job at hand, you work faster and better. More surprising is the result that, when you are less skilled, a GAI tool provides a greater amount of help. It is not often that a tool levels the playing field, helping novices more than power users.</p>
<p>Yet, on tasks <em>outside</em> the frontier (i.e., where the GAI tool is often wrong), the authors found:</p>
<ul class="simple">
<li><p>Consultants using a GAI tool were “19 percentage points <em>less likely</em> to produce correct solutions compared to those without.” [Emphasis added.]</p></li>
<li><p>Plus, those who were instructed on ways to write better prompts produced <em>worse results</em>. [Emphasis added.]</p></li>
</ul>
<p>Clearly, understanding a tool’s frontier matters.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>As a user of GAI tools, you need to know on what tasks a tool works well and not be lulled into blindly accepting what it produces. The companies producing GAI tools, for competitive reasons, won’t often tell you where this frontier is. Furthermore, as this third act has emphasized, it is not sufficient to learn how to use a tool. You must also understand its limitations.</p>
</div>
<p>While the capabilities of GAI tools will continue to improve, there will always be a frontier. With a general understanding of how GAI tools work and a little bit of critical thinking, you can discover a tool’s frontier. In the rest of this chapter, I’ll demonstrate this for the task of problem solving with computation using OpenAI’s GPT-4. By focusing your interactions with a GAI tool where you need help and it is capable, you’ll be able to supercharge your newly-acquired problem-solving skills.</p>
</section>
<section id="my-use-of-gai">
<p><strong>My use of GAI.</strong> I just made a claim that isn’t too different than you see from any company building or employing GAI: This technology is powerful, and it is going to change the way many of us work. But it is still early days, and only time will tell how things will change. We can, however, accelerate this discovery process by explaining to each other how we have used GAI in our own work.</p>
<p>For me, this begins with a disclosure that I’m using a GAI tool:</p>
<div class="admonition-how-i-used-gai admonition">
<p class="admonition-title">How I Used GAI</p>
<p>I acknowledge the use of OpenAI’s ChatGPT (GPT-4) in the development of this chapter’s content. The chapter’s ideas, main points, and organization are entirely mine, and except where indicated, the text and code examples are mine.</p>
</div>
<p>For example, I asked GPT-4 to briefly describe GAI for students in a computational thinking class, and the last sentence in its response, which I’ve bolded below, is something I decided to highlight more prominently in writing this chapter than I had in outlining it.</p>
<blockquote>
<div><p><strong>Me:</strong> What is generative artificial intelligence?</p>
<p><strong>ChatGPT:</strong> Generative Artificial Intelligence is a type of AI that focuses on creating new content. It’s like an AI artist that can independently create something new rather than simply analyzing and understanding existing content. Examples of generative AI include AI systems that can generate music, images, or text. <strong>In a computational thinking context, the concept of generative systems helps us understand how complex output can emerge from simple rules and structures.</strong></p>
</div></blockquote>
<p>This example illustrates one of the ways I think about using a GAI tool. The full framework involves asking the following three questions:</p>
<ul class="simple">
<li><p>Do I want to <strong>delegate</strong> some of my work to the GAI tool? I answer yes when <em>I want the outcome</em> (e.g., a summary of a long essay, or finding and understanding a bug in my Python program), but <em>the process of producing the outcome is not something I need to do</em>.</p></li>
<li><p>Do I want the GAI tool to <strong>nudge</strong> along my creativity? I answer yes when I think that the GAI tool might help me expand upon my initial ideas or generate a broader set of examples. This is what I did above. <em>I want the outcome</em> (e.g., a chapter that appeals to a wide range of readers), and it’s important that <em>I’m intimately involved in the process of generating it</em>.</p></li>
<li><p>Do I want the GAI tool to <strong>check and suggest corrections</strong> for the details in my work? I answer yes when <em>my work is near completion</em> and <em>I’m looking for feedback, improvements, or corrections</em>. Machines, which don’t get distracted or tired, are often better than humans in carefully checking the details.</p></li>
</ul>
<p>We’ll use this framework throughout this chapter, and I hope you find it useful in your own interactions with different GAI tools.</p>
</section>
<section id="large-language-models-llms">
<p><strong>Large Language Models (LLMs).</strong> To navigate the jagged frontier of a GAI tool, it helps to have a basic understanding of how they work. In particular, I’ll briefly describe the functioning of Large Language Models (LLMs), which are the foundation for today’s AI coding assistants.<a class="footnote-reference brackets" href="#fn2" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> GPT-4 is a LLM and one of the multiple models that powers the chat interface that is ChatGPT. While I’ll focus on GPT-4, what you’ll learn is equally applicable to the LLMs available from other companies.</p>
<p>LLMs are essentially functions that map a text input to a text output.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_text</span> <span class="o">=</span> <span class="s1">&#39;What is generative artificial intelligence?&#39;</span>
<span class="n">output_text</span> <span class="o">=</span> <span class="n">GPT4</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
</pre></div>
</div>
<p>More specifically, LLMs attempt to create a <em>reasonable continuation</em> of the text input. To understand what this means, think of a conversation between two people. You’d expect the second-to-speak person’s utterances (i.e., ChatGPT’s response) will be related to what the first person (i.e., you) just said (i.e., your prompt to ChatGPT). In other words, <code class="docutils literal notranslate"><span class="pre">output_text</span></code> is ChatGPT’s reasonable conversational response to your prompt <code class="docutils literal notranslate"><span class="pre">input_text</span></code>.</p>
<p>When speaking with another human being, our reasonable continuations rely on:</p>
<ul class="simple">
<li><p>shared understandings from our common experiences;</p></li>
<li><p>the human capacity to put ourselves in another’s shoes (i.e., empathy); and</p></li>
<li><p>societal norms.</p></li>
</ul>
<p>Machines have none of these things, but they can generate what some people might likely say in a particular context based on prior analysis of:</p>
<ul class="simple">
<li><p>the text on the billions of web sites across the internet;</p></li>
<li><p>the content in the millions of digitized books; and</p></li>
<li><p>the transcripts of many online videos.</p></li>
</ul>
<p>LLMs are a classic use of online and offline work, where the offline work is the kind that we covered in the previous chapter:</p>
<ol class="arabic simple">
<li><p>Offline: create a huge dataset of human writings.</p></li>
<li><p>Offline: train and validate a prediction model using this dataset.</p></li>
<li><p>Offline: tweak the model with human feedback, which you can think of as socializing the model’s responses with help from humans.</p></li>
<li><p>Online: grab a human’s prompt and use the model to repeatedly predict the words that would likely come next, with some idea of when it’s good to stop speaking (i.e., end the model’s response).</p></li>
</ol>
</section>
<section id="the-operation-of-llms">
<p><strong>The operation of LLMs.</strong> For his article, Stephen Wolfram [2023] uses an earlier and smaller version of OpenAI’s GPT system (GPT-2) to describe the computational work being done in the final online step. As he explains, what looks to us through the ChatGPT interface as a prompt and a lengthy response is actually multiple calls to the GPT model.</p>
<p>Let’s take these calls one at a time. Wolfram’s example, which I’ll describe here, begins with the prompt string <code class="docutils literal notranslate"><span class="pre">&quot;The</span> <span class="pre">best</span> <span class="pre">thing</span> <span class="pre">about</span> <span class="pre">AI</span> <span class="pre">is</span> <span class="pre">its</span> <span class="pre">ability</span> <span class="pre">to&quot;</span></code> and GPT-2 responds with (roughly<a class="footnote-reference brackets" href="#fn3" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>) a word that is a reasonable continuation to it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">the_next_word</span> <span class="o">=</span> <span class="n">GPT2</span><span class="p">(</span><span class="s2">&quot;The best thing about AI is its ability to&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s suppose that GPT-2 returns the word “learn”. From its training, the model has discovered this word comes next in contexts like this, but “learn” is not the only reasonable continuation it computes. Wolfram reports that GPT-2 also generates “predict”, “make”, “understand”, “do”, and many other words as possible continuations. In fact, GPT-2 computes with each generated word what we can think of as a probability; the higher the probability the more likely it is that the word is a reasonable continuation based on its training.</p>
<p>In order to return one of these generated words, GPT-2 has to make a choice, as illustrated in <a class="reference internal" href="#c18-fig2-ref"><span class="std std-numref">Figure 37</span></a>. Should it select “learn” which is the choice with the highest computed probability? Or should it select one of the other highly ranked words?</p>
<figure class="align-default" id="c18-fig2-ref">
<img alt="_images/c18_fig2.png" src="_images/c18_fig2.png" />
<figcaption>
<p><span class="caption-number">Fig. 37 </span><span class="caption-text">The top five most likely words in Wolfram’s example that GPT-2 predicts will reasonably continue the prompt “The best thing about AI is its ability to”.</span><a class="headerlink" href="#c18-fig2-ref" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Through experience, LLM developers have discovered that models that always return the highest-ranked next word produce responses that sound flat and repetitious to humans. Models with more natural-sounding responses vary the choice of words from those most highly ranked.<a class="footnote-reference brackets" href="#fn4" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></p>
<p>But let’s continue with Wolfram’s example and have the model chose “learn” from this list. The conversation’s context is now “The best thing about AI is its ability to learn” and the next step is to call GPT-2 with this string. The model provides the next word (e.g., the word “from”) and we again update the context. We have now defined the body of a loop: the model chooses a word that is a reasonable continuation of its current context and then uses its choice to update the context.</p>
<p>The next obvious question is: what is this loop’s exit condition? As we’ve learned, loops need at least one. A straightforward answer to this question is to use a special END token. The model generates a probability for END on each call, and when this token is selected, the model has determined that it is reasonable to end the loop and return the response.</p>
</section>
<section id="complexity-from-simplicity">
<p><strong>Complexity from simplicity.</strong> Earlier, when I asked ChatGPT to explain GAI, it responded that these systems help us to “understand how complex output can emerge from simple rules and structures.” This statement refers to the building blocks and basic layout of a LLM (and many other AI models like image recognizers), which I’ll now briefly describe. My point is not to have you comprehend all the details, but to realize that a GAI model isn’t constructed and programmed like a calculator or spreadsheet application. Structurally, GAI models are <em>neural networks</em>, which were inspired by the biological structure of the human brain (i.e., the brain’s networks of neurons).</p>
<p>Neural networks were first proposed in the 1940s, and today’s computational neurons are largely unchanged since then. What’s changed is the computing speed of these neurons, the number of them we can interconnect and train, and the size of the training data sets. Everything has gotten orders of magnitude faster and bigger.</p>
<p><a class="reference internal" href="#c18-fig3-ref"><span class="std std-numref">Figure 38</span></a> is a typical and idealized illustration of a neural network. It is comprised of computational neurons (i.e., the circles in the figure) that are organized into layers. Inputs to the model are fed to the first layer of neurons, which compute with these inputs and whose outputs are fed to the next layer of neurons. This feed-forward organization continues until the last layer outputs the model’s result.</p>
<figure class="align-default" id="c18-fig3-ref">
<img alt="_images/c18_fig3.png" src="_images/c18_fig3.png" />
<figcaption>
<p><span class="caption-number">Fig. 38 </span><span class="caption-text">The rough structure of a neural network. It is a directed graph where values flow along the edges (arrows) and are treated as weighted inputs to the nodes (circles), which represent the computational neurons. Each neuron performs a fairly simple numerical computation.</span><a class="headerlink" href="#c18-fig3-ref" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The thickness of the arrows in <a class="reference internal" href="#c18-fig3-ref"><span class="std std-numref">Figure 38</span></a> varies to represent that the values carried along each edge are weighted before being used in a neuron’s computation. If we pull that weighting into the work done at an individual neuron, the output value of a neuron is:</p>
<ul class="simple">
<li><p>the sum of the weighted values on the  <span class="math notranslate nohighlight">\(n\)</span> incoming edges: <span class="math notranslate nohighlight">\(\sum_{i=1}^{n} (w_i * x_i)\)</span> where <span class="math notranslate nohighlight">\(w\)</span> is a weight and <span class="math notranslate nohighlight">\(x\)</span> is an incoming value;</p></li>
<li><p>plus a constant <span class="math notranslate nohighlight">\(b\)</span>;</p></li>
<li><p>followed by a <em>thresholding</em> or <em>activation</em> function <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
</ul>
<p>Each computational neuron in a model’s neural network typically has its own set of weights for the incoming edges and its own constant <span class="math notranslate nohighlight">\(b\)</span>. These are the <em>parameters</em> that you hear mentioned when a company quantifies the complexity of its model. They are also what are set through training, as we’ll discuss next.</p>
<p>The thresholding or activation function is typically the same across all computational neurons in a layer. More interesting is its purpose, which is to allow for nonlinear behavior out of a layer.</p>
<p>While a neuron’s computation may not sound simple to you, it is much simpler than all but the most trivial of the programs we’ve been writing throughout this book. Perhaps someday someone will figure out how human-sounding responses come from such simple structures, but as of today, we can’t explain it. Furthermore, engineering a useful neural network continues to be more of an art than a science.</p>
</section>
<section id="training-a-neural-network">
<p><strong>Training a neural network.</strong> Training a neural network (i.e., setting its parameters) relies on a combination of straightforward calculus and engineering art. The calculus is not important to achieve the goals of this chapter. By engineering art, I mean that the success of today’s LLMs depends significantly on many seemingly arbitrary engineering decisions. It also takes a lot of time, money, and training data. We got an inkling of this challenge in the last chapter.</p>
<p>But at a high level, we can train an LLM using supervised learning. We take sentences from our corpus of real-world examples and mask out the ends of them. We then measure the difference between the model’s answer and the actual sentence endings. Using this difference, we nudge the model toward better responses by changing its parameters. LLM developers continue to do this until they’re happy with the model’s responses. Again, this should remind you of the ML work we discussed in the last chapter, although measuring the difference between words is not as simple as the difference between home prices.</p>
<p>To make this concrete, consider the following start to a sentence: “The sky is _____”. From our data set of real-world sentences, we know that “blue”, “stormy”, “falling”, “endless”, and “empty” are all reasonable continuations while “able” and “tape” are not. Which word from the first list should the model give the highest priority? That would depend upon the context of the conversation before this sentence.</p>
<p>My last point hints at something you should understand that LLMs are not doing. They are not a really big hash table that hashes the input prompt to access a stored list of reasonable words. If you think about it for a moment (or do the math that Wolfram [2023] describes), you’ll quickly realize that there are too many prefix possibilities to even conceive of building such a table. This also means that the training set cannot contain every possible user prompt, since it is of a large but limited size.</p>
<p>But this is all ok. LLMs are exactly what the M in the acronym stands for: a model. The word probabilities generated by a model like GPT-4 are just estimates informed by its training. The word it generates needs to fit the patterns seen in the training set, not any particular example. If it helps, recall that the sales-price predictor in the last chapter used attributes of a previously unseen house to predict this home’s sales price. This home didn’t have to be in the training set.</p>
<div class="tip admonition">
<p class="admonition-title">Terminology</p>
<p>The acronym GPT in the ChatGPT application name and GPT-x model names stands for “Generative Pre-trained Transformer” and you now can explain the first two terms. Its last term, Transformer, refers to a specific architecture of neural networks that focuses the model’s attention on particular parts of the input prompt. It’s kind of like choosing the right set of attributes on which to focus our sales-price predictor.</p>
</div>
</section>
<section id="two-pieces-to-problem-solving-with-gai">
<p><strong>Two pieces to problem solving with GAI.</strong> It’s time to get back to problem solving. At the start of this chapter, I demonstrated how a context specified through a prompt and a model trained on all the Python examples in GitHub and elsewhere online could, through reasonable continuations, create a working Python script for the problem described in the prompt. Will this always work? Well, it depends on:</p>
<ol class="arabic simple">
<li><p>how competent we are at providing a “good” prompt; and</p></li>
<li><p>whether the problem we want solved is within or beyond the model’s frontier.</p></li>
</ol>
<p>We haven’t spoken about what makes a good prompt, but we will. On the other hand, the preceding discussion provided some foundational knowledge with which we can think critically about a model’s response to a prompt. Our goal in this thinking is to decide whether the task we’ve given a GAI tool is within or beyond its frontier. And when it is beyond its capabilities, I’ll show you how you can nonetheless benefit by combining the tool with the skills and knowledge in this book.</p>
</section>
<section id="an-easy-request">
<p><strong>An easy request?</strong> As we’ve done in every other chapter, let’s proceed with a problem-to-be-solved. Here’s the setup: When I teach my introductory computer science course using this book, I have the students practice their knowledge of goal-directed search (Chapter 11) by writing a program that plays the parlor game <a class="reference external" href="https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon">Six Degrees of Kevin Bacon</a>. In this game, players challenge each other to connect two given actors by:</p>
<ol class="arabic simple">
<li><p>describing a chain of actors, bracketed by the two given actors; and</p></li>
<li><p>for each pair of consecutive actors in the chain, naming a movie in which they both co-starred.</p></li>
</ol>
<p>For example, Kevin Bacon and Marlon Brando are connected through Jack Nicholson because:</p>
<ul class="simple">
<li><p>Bacon and Nicholson starred together in <em>A Few Good Men</em></p></li>
<li><p>Nicholson and Brando starred together in <em>The Missouri Breaks</em></p></li>
</ul>
<p>The chain Bacon-Nicholson-Brando is said to have a <em>degrees-of-separation</em> measure of two, i.e., it took two steps (or movies) to go from Bacon to Nicholson.</p>
<p>My students test their programs on a small slice of the <a class="reference external" href="https://developer.imdb.com/non-commercial-datasets/">IMDb data sets</a>, and when they think their code works, I ask them to try it on a much larger slice. My pedagogical goal is to demonstrate that your code may functionally work, but large data sets can stress it in ways small data sets don’t (e.g., quickly show you where your code is inefficiently implemented). The chain I showed with Bacon, Nicholson, and Brando is found through a breadth-first search on the large IMDb data set, and when running a depth-first search, their programs often produce answers with much larger degrees of separation. The graph of actors and movies is highly interconnected, and there exist many chains from Bacon to Nicholson. Without fail, the students will come to me and ask if their script’s depth-first output, like the following that reports 66 degrees of separation, is correct. I look at them and say, “I don’t know. How would you check this output?”</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Name: Which &#39;kevin bacon&#39;?
ID: 9323132, Name: Kevin Bacon, Birth:
ID: 102, Name: Kevin Bacon, Birth: 1958
Intended Person ID: Name: Running a dfs search
66 degrees of separation.
1: Kevin Bacon and John Goodman starred in Death Sentence
2: John Goodman and Carey Mulligan starred in Inside Llewyn Davis
3: Carey Mulligan and Joel Edgerton starred in The Great Gatsby
4: Joel Edgerton and Hanna Mangan Lawrence starred in Acolytes
5: Hanna Mangan Lawrence and Aden Young starred in Dark Frontier
6: Aden Young and Marshall Napier starred in Shotgun Wedding
7: Marshall Napier and Bruce Lyons starred in The Navigator: A Medieval Odyssey
...
64: Mimi Denissi and Louis-Do de Lencquesaing starred in Blind Sun
65: Louis-Do de Lencquesaing and Marthe Keller starred in The Holy Family
66: Marthe Keller and Marlon Brando starred in The Formula
</pre></div>
</div>
<div class="admonition-you-try-it admonition">
<p class="admonition-title">You Try It</p>
<p>Take a moment to understand this captured output, including its first four lines. I captured this output by directing the solution script’s standard output, as we discussed in Chapter 13. Because I only captured the script’s standard output, you don’t see my answers to the script’s <code class="docutils literal notranslate"><span class="pre">input</span></code> prompts, which traveled over the script’s standard input. At the first occurrence of <code class="docutils literal notranslate"><span class="pre">Name:</span></code>, the script asked for the first actor’s name, to which I responded “kevin bacon”. The next question comes on the same output line because the newline character was in my response. The output <code class="docutils literal notranslate"><span class="pre">Which</span> <span class="pre">'kevin</span> <span class="pre">bacon'?</span></code> and the two ID lines occurred because there are two actors with this name in the IMDb data set, and the script wants to know which one I meant. To the <code class="docutils literal notranslate"><span class="pre">Intended</span> <span class="pre">Person</span> <span class="pre">ID:</span></code> prompt, I responded “102”. The script then asks for the second actor’s name, and I typed “Marlon Brando”. With the data it needs, the script then states it had begun running a depth-first search (DFS). It reports finding a chain with 66 degrees of separation and prints the details of it.</p>
</div>
<p>The copy of the output above doesn’t show all 66 lines in the chain, but hopefully you see the pattern: Each line is of the form “ACTOR1 and ACTOR2 starred in MOVIE” where the uppercase nouns are placeholders for actor names and movie titles. A properly-functioning goal-directed search, as we discussed in Chapter 11, shouldn’t visit the same node (i.e., actor) more than once. This means that no actor should appear in the last 66 lines more than twice.</p>
<p>To check this, we have three options:</p>
<ol class="arabic simple">
<li><p>Check the list by hand counting the occurrences of each name.</p></li>
<li><p>Write a Python script to analyze this output as we would have done by hand.</p></li>
<li><p>Ask ChatGPT to do it for us.</p></li>
</ol>
<p>The students are asking me because Option 1 is undesirable and error-prone. Using my earlier framework, this problem-to-be-solved is a classic example of work everyone wants to delegate.</p>
</section>
<section id="write-the-script-ourselves">
<p><strong>Write the script ourselves.</strong> Option 2 isn’t hard. We learned in Chapter 13 how to use regular expressions (REs) to pull out pieces of text from blurbs that follow a pattern, and it’s straightforward to use a Python dictionary to keep track of how many times we saw each name. After about an hour’s worth of work, including some googling of syntax and test runs to verify that my code functioned properly, I had a function <code class="docutils literal notranslate"><span class="pre">check</span></code> that solved this problem.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1">### chap18/check_chain.py</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">re</span>
<span class="linenos"> 3</span><span class="kn">import</span> <span class="nn">sys</span>
<span class="linenos"> 4</span>
<span class="linenos"> 5</span><span class="c1"># Terminal colors</span>
<span class="linenos"> 6</span><span class="n">reset</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\033</span><span class="s1">[0m&#39;</span>
<span class="linenos"> 7</span><span class="n">red</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\033</span><span class="s1">[31m&#39;</span>
<span class="linenos"> 8</span><span class="n">blue</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\033</span><span class="s1">[34m&#39;</span>
<span class="linenos"> 9</span>
<span class="linenos">10</span><span class="k">def</span> <span class="nf">increment</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<span class="linenos">11</span><span class="w">    </span><span class="sd">&#39;&#39;&#39;Increment the count for key `key` in dictionary `d`&#39;&#39;&#39;</span>
<span class="linenos">12</span>    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
<span class="linenos">13</span>        <span class="k">if</span> <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">14</span>            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Actor &quot;</span><span class="si">{</span><span class="n">red</span><span class="si">}{</span><span class="n">key</span><span class="si">}{</span><span class="n">reset</span><span class="si">}</span><span class="s1">&quot; occurs too many times&#39;</span><span class="p">)</span>
<span class="linenos">15</span>            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">()</span>
<span class="linenos">16</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">17</span>            <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos">18</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos">19</span>        <span class="n">d</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="linenos">20</span>
<span class="linenos">21</span><span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="n">lines</span><span class="p">):</span>
<span class="linenos">22</span><span class="w">    </span><span class="sd">&#39;&#39;&#39;Make sure no actor occurs more than twice&#39;&#39;&#39;</span>
<span class="linenos">23</span>    
<span class="linenos">24</span>    <span class="c1"># Dictionary where we keep a count of instances of each actor</span>
<span class="linenos">25</span>    <span class="n">count</span> <span class="o">=</span> <span class="p">{}</span>
<span class="linenos">26</span>    
<span class="linenos">27</span>    <span class="c1"># Compile the fancy RE</span>
<span class="linenos">28</span>    <span class="n">the_re</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;\d+:\s+([ \-</span><span class="se">\&#39;</span><span class="s1">\w]+) and ([ \-</span><span class="se">\&#39;</span><span class="s1">\w]+) starred in (.*)$&#39;</span>
<span class="linenos">29</span>    <span class="n">p</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">the_re</span><span class="p">)</span>
<span class="linenos">30</span>    
<span class="linenos">31</span>    <span class="c1"># Process each line grabbing the actors and the movie</span>
<span class="linenos">32</span>    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
<span class="linenos">33</span>        <span class="c1"># Skip any blank lines</span>
<span class="linenos">34</span>        <span class="k">if</span> <span class="n">line</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
<span class="linenos">35</span>            <span class="k">continue</span>
<span class="linenos">36</span>        
<span class="linenos">37</span>        <span class="c1"># Run match on current line</span>
<span class="linenos">38</span>        <span class="n">m</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
<span class="linenos">39</span>        
<span class="linenos">40</span>        <span class="c1"># Error checking</span>
<span class="linenos">41</span>        <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">42</span>            <span class="c1"># I missed a case for the RE</span>
<span class="linenos">43</span>            <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;Died on line: </span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="s1">&#39;</span>
<span class="linenos">44</span>        
<span class="linenos">45</span>        <span class="c1"># Pull out the parts</span>
<span class="linenos">46</span>        <span class="n">actor1</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos">47</span>        <span class="n">actor2</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos">48</span>        <span class="n">movie</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>   <span class="c1"># currently unused</span>
<span class="linenos">49</span>        
<span class="linenos">50</span>        <span class="c1"># Put the actors in the dictionary</span>
<span class="linenos">51</span>        <span class="n">increment</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">actor1</span><span class="p">)</span>
<span class="linenos">52</span>        <span class="n">increment</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">actor2</span><span class="p">)</span>                
<span class="linenos">53</span>    
<span class="linenos">54</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">blue</span><span class="si">}</span><span class="s1">No repeated actors!</span><span class="si">{</span><span class="n">reset</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>In designing this function, I decided that its formal parameter <code class="docutils literal notranslate"><span class="pre">lines</span></code> would expect only the lines that fit the pattern: <code class="docutils literal notranslate"><span class="pre">ACTOR1</span> <span class="pre">and</span> <span class="pre">ACTOR2</span> <span class="pre">starred</span> <span class="pre">in</span> <span class="pre">MOVIE</span></code>. As such, I do a bit of preprocessing on the captured output before invoking <code class="docutils literal notranslate"><span class="pre">check</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">58</span><span class="c1">### chap18/check_chain.py</span>
<span class="linenos">59</span>
<span class="linenos">60</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="nb">input</span><span class="p">(</span><span class="s1">&#39;Filename? &#39;</span><span class="p">))</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
<span class="linenos">61</span>    <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="linenos">62</span>    
<span class="linenos">63</span>    <span class="c1"># Figure out how many initial lines to remove</span>
<span class="linenos">64</span>    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos">65</span>    <span class="k">while</span> <span class="s1">&#39;degrees of separation&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
<span class="linenos">66</span>        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos">67</span>    
<span class="linenos">68</span>    <span class="n">check</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
<div class="admonition-you-try-it admonition">
<p class="admonition-title">You Try It</p>
<p>Run <code class="docutils literal notranslate"><span class="pre">check</span></code> as demonstrated on the output I showed earlier. The GitHub repository associated with this book contains the full text file (<code class="docutils literal notranslate"><span class="pre">test_wo_error.txt</span></code>) I showed above and two other text files that this function will flag as containing errors.</p>
</div>
</section>
<section id="ask-chatgpt">
<p><strong>Ask ChatGPT.</strong> While Option 2 isn’t hard, perhaps we could save the hour I took producing <code class="docutils literal notranslate"><span class="pre">check</span></code> and ask ChatGPT to check the output directly. ChatGPT allows you to upload a file with your prompt. So I uploaded <code class="docutils literal notranslate"><span class="pre">test_wo_errors.txt</span></code> and asked: “Are any of the names in the attached text repeated more than twice?” ChatGPT replied:</p>
<blockquote>
<div><p><strong>ChatGPT:</strong> Upon analyzing the text, I found that the name “Kevin Bacon” appears twice in the document. There are no other names repeated more than twice in the text provided.</p>
</div></blockquote>
<p>It’s true that “Kevin Bacon” appears more than twice because I forgot to ask ChatGPT to ignore the first several lines, as I did when running my <code class="docutils literal notranslate"><span class="pre">check</span></code> function.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You still need to think when you ask a GAI tool to do your work.</p>
</div>
<p>But ChatGPT’s first sentence in the response doesn’t really make much sense. I asked if any names appeared <em>more than twice</em>, and while it correctly identified “Kevin Bacon” as appearing too many times, it wrote that this name “<em>appeared twice</em> in the document.” [Emphasis added.] This caused me to ask, “please explain how you came to that answer” and it replied:</p>
<blockquote>
<div><p><strong>ChatGPT:</strong> To determine if any names were repeated more than twice in the text file, I performed a search in the file’s contents for all occurrences of names. This search was conducted using the uploaded file’s content where names were explicitly identified, and the data was systematically checked for repetitions.</p>
<p>In the file, “Kevin Bacon” is mentioned twice explicitly in different contexts (as part of an identification process and in a detailed listing related to “degrees of separation”). I reviewed the list of other names that appear throughout the text, each linked to various interactions and connections, but none were mentioned more than twice.</p>
<p>Based on this analysis, I concluded that “Kevin Bacon” is the only name that appears twice, and no names exceed this number of mentions in the text.</p>
</div></blockquote>
<p>This sounds good albeit that it’s quite a high-level description. I’m thinking now and so I decided to see if ChatGPT could really find a name repeated more than twice when that name occurred only in the part of the file that mattered (i.e., the chain of actor names). I copied the original output, duplicated the last line, and inserted Louis-Do de Lencquesaing between Marthe Keller and Marlon Brando in the chain of actors. Notice that Lencquesaing also occurs at chain links 64 and 65. Here’s the end of this new test file, which I called <code class="docutils literal notranslate"><span class="pre">test_w_error2.txt</span></code>.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Name: Which &#39;kevin bacon&#39;?
ID: 9323132, Name: Kevin Bacon, Birth:
ID: 102, Name: Kevin Bacon, Birth: 1958
Intended Person ID: Name: Running a dfs search
66 degrees of separation.
1: Kevin Bacon and John Goodman starred in Death Sentence
...
64: Mimi Denissi and Louis-Do de Lencquesaing starred in Blind Sun
65: Louis-Do de Lencquesaing and Marthe Keller starred in The Holy Family
66: Marthe Keller and Louis-Do de Lencquesaing starred in I Made This Up
66: Louis-Do de Lencquesaing and Marlon Brando starred in The Formula
</pre></div>
</div>
<p>The following is my prompt and ChatGPT’s answer:</p>
<blockquote>
<div><p><strong>Me:</strong> Please tell me which names are mentioned more than twice in the attached text file. [I attached <code class="docutils literal notranslate"><span class="pre">test_w_error2.txt</span></code>.]</p>
<p><strong>ChatGPT:</strong> After reviewing the attached text file and analyzing the content for repeated names, here are the findings:</p>
<ol class="arabic simple">
<li><p><strong>Kevin Bacon</strong> - Mentioned twice.</p></li>
<li><p><strong>Louis-Do de Lencquesaing</strong>- Mentioned three times.</p></li>
<li><p><strong>John Goodman</strong>, <strong>Carey Mulligan</strong>, <strong>Joel Edgerton</strong>, <strong>Heidi Armbruster</strong>, and <strong>Marthe Keller</strong> - Each mentioned twice.</p></li>
</ol>
<p><strong>Louis-Do de Lencquesaing</strong> is the only name that appears more than twice in the document. This conclusion was reached by methodically going through each line of the text and counting the occurrences of each name, focusing especially on those that appear multiple times.</p>
</div></blockquote>
<p>ChatGPT correctly finds that Louis-Do de Lencquesaing is mentioned too many times, but it still struggles with counting. And it strangely tells me about a few but not all the other actors mentioned twice.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>ChatGPT works quickly, but you’ll spend additional time debugging its work.</p>
</div>
<p>At this point, I haven’t found a prompt that causes ChatGPT to tell me exactly what I want to know and in a manner that makes me confident of its work. The reason I’m not getting a good result from ChatGPT could be that: (1) my skills in prompting need improvement; or (2) this task is beyond the model’s frontier. These are exactly the two challenges I mentioned earlier in problem solving with GAI. Let’s deal with them one at a time.</p>
</section>
<section id="is-this-task-within-the-frontier">
<p><strong>Is this task within the frontier?</strong> There’s no easy answer to this question because no one can yet explain exactly how a GAI tool is capable of solving the kind of task we just gave GPT-4. We can build these models, but we cannot explain how a prompt produces a specific response. There are many smart researchers working on this challenge of <em>explainability</em> in GAI systems.</p>
<p>Until this challenge is solved, I use a heuristic. We talked about heuristics in Chapter 11. They are approximate methods that largely but not perfectly answer a hard question. A good heuristic is practical to compute and not badly wrong. So what is a heuristic method for deciding whether your task is within your GAI tool’s frontier?</p>
<p>My approach flips the challenge of explainability on its head. Instead of a human trying to explain to another human how a GAI tool came to the particular response, I request the GAI tool to explain how it came to that response. If it provides me with an understandable explanation, I’ll believe that the task is within its frontier. When it doesn’t convince me, one of the following three things is true:</p>
<ol class="arabic simple">
<li><p>The task is outside the model’s frontier, and it can’t provide a convincing explanation because it didn’t actually solve the task (e.g., it hallucinated a solution).</p></li>
<li><p>The task is within the model’s frontier, but explaining to me what it did is not within its frontier.</p></li>
<li><p>The task and the ability to explain the solution are within the model’s frontier, but I’m not smart enough to understand the explanation.</p></li>
</ol>
<p>I can’t tell the difference between these three cases, but I don’t have to. If I assume the GAI tool can’t solve the task whenever it can’t convince me, I won’t use an incorrect solution. This conservative approach also has the nice property that it will improve as the capabilities of GAI tools improve (and as I become smarter).</p>
<p>You’ve previously seen me using this approach with ChatGPT. Assuming the prompts I used were clear and unambiguous (an issue we’ll explore later), I can conclude through our prior work with GPT-4 that it isn’t fully capable of robustly solving our problem-to-be-solved.</p>
</section>
<section id="the-expanding-frontier">
<p><strong>The expanding frontier.</strong> As an example of GAI’s expanding frontier, Wolfram [2023] describes the training of a GPT-2-like model for recognizing and producing sequences of balanced parentheses, as one sees in mathematical and programming language expressions. The model works well for short sequences of opening parentheses (e.g., the model correctly responds that it should follow <code class="docutils literal notranslate"><span class="pre">(((</span></code> with <code class="docutils literal notranslate"><span class="pre">)))</span></code>), but the highest-probability completion for long sequences of opening parentheses doesn’t always produce a response that’s balanced. Wolfram [2023] theorizes that this model can reliably solve only things that humans can solve at a glance. When humans need to start counting and matching parentheses, the model should too and GPT-2 doesn’t.</p>
<p>I’m not limited to GPT-2, and so I asked GPT-4 to “generate a balanced set of parentheses” and gave it a number of examples (i.e., what’s called <em>few-shot prompting</em> as we’ll discuss later). GPT-4 correctly solved the long sequences that GPT-2 couldn’t. When I asked GPT-4 to explain its work, it showed me a piece of Python code, which I have put in <code class="docutils literal notranslate"><span class="pre">balance_parentheses.py</span></code> in the book’s GitHub repository. In other words, unlike GPT-2, GPT-4 was “smart enough” to realize it should built an algorithmic solution and use it. More tasks were inside its frontier than GPT-2.</p>
<p>Unfortunately, not all tasks are inside GPT-4’s frontier for it became anchored in the context. When I continued to prompt it and provided the prefix <code class="docutils literal notranslate"><span class="pre">()())</span></code>, which can’t be made balanced by adding more parentheses, it responded: “The input <code class="docutils literal notranslate"><span class="pre">()())</span></code> is already balanced, so the output remains <code class="docutils literal notranslate"><span class="pre">()())</span></code>.” The reason it gave for the answer was the same <code class="docutils literal notranslate"><span class="pre">balance_parentheses.py</span></code> code, which doesn’t check for the condition in my example.</p>
</section>
<section id="how-to-problem-solve-with-a-llm">
<p><strong>How to problem solve with a LLM.</strong> Now that we’ve decided the complete problem-to-be-solved from my introductory computer science class is not within GPT-4’s frontier, how should we proceed to get benefit from the use of it? Simple, we decompose this problem into its tasks as if we were going to solve it ourselves, and then ask for GPT-4’s help in solving the most difficult of these smaller tasks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Grab the filename and read in its lines</span>
<span class="c1"># Strip off the lines up to and including &#39;degrees of separation&#39;</span>
<span class="c1"># Grab the names out of each line and insert them in a dictionary</span>
<span class="c1"># If the value associated with a name exceeds 2, we have a problem</span>
</pre></div>
</div>
<p>The hardest task in this decomposition is grabbing the names from each line. So let’s ask ChatGPT to help with that:</p>
<blockquote>
<div><p><strong>Me:</strong> Please write me a Python function that removes the names from a line like “Carey Mulligan and Joel Edgerton starred in The Great Gatsby”</p>
<p><strong>ChatGPT:</strong> To remove the names from a sentence like “Carey Mulligan and Joel Edgerton starred in The Great Gatsby,” we can create a Python function that identifies patterns resembling names (typically capitalized words) and removes them. This approach assumes that names are the capitalized words before the verb “starred” in the sentence.</p>
<p>Here’s a Python function that employs regular expressions to identify and remove these patterns:</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1">### chap18/remove_names.py -- Written by ChatGPT</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">re</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="k">def</span> <span class="nf">remove_names_from_line</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
<span class="linenos"> 5</span>    <span class="c1"># Pattern to find capitalized words followed by &#39;and&#39; or &#39;starred&#39;</span>
<span class="linenos"> 6</span>    <span class="c1"># This regex assumes that names are always before &#39;starred&#39; and start with capital letters</span>
<span class="linenos"> 7</span>    <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;\b[A-Z][a-z]*\s(?:and\s)?[A-Z][a-z]*\s(starred)&#39;</span>
<span class="linenos"> 8</span>    
<span class="linenos"> 9</span>    <span class="c1"># Replace the names and &#39;and&#39; if it appears with &#39;starred&#39;</span>
<span class="linenos">10</span>    <span class="c1"># This keeps the structure of the sentence but removes the names</span>
<span class="linenos">11</span>    <span class="n">clean_line</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;\1&#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span>
<span class="linenos">12</span>    
<span class="linenos">13</span>    <span class="k">return</span> <span class="n">clean_line</span>
<span class="linenos">14</span>
<span class="linenos">15</span><span class="c1"># Example usage</span>
<span class="linenos">16</span><span class="n">line</span> <span class="o">=</span> <span class="s2">&quot;Carey Mulligan and Joel Edgerton starred in The Great Gatsby&quot;</span>
<span class="linenos">17</span><span class="nb">print</span><span class="p">(</span><span class="n">remove_names_from_line</span><span class="p">(</span><span class="n">line</span><span class="p">))</span>
</pre></div>
</div>
<p>When you run this script, it prints: `Carey Mulligan and starred in The Great Gatsby`. ChatGPT took me literally and removed the second actor’s name from the line. This is not the interpretation of my prompt that I wanted. English is ambiguous!</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>While “programming” a GAI in English (or any human language) might make problem solving with computation accessible to more people across the world, there’s a reason why programming languages attempt to have well-defined semantics.</p>
</div>
<p>Still, ChatGPT gave us a starting point for a solution and an explanation (not shown) of what went into the regular-expression pattern it used. We’ll likely solve our problem faster with this assistance.</p>
</section>
<section id="writing-good-prompts">
<p><strong>Writing good prompts.</strong> Now that you’ve seen some prompts, it’s finally time to discuss what makes a good one. This topic is also called <em>prompt engineering</em>. I begin with three often-recommended ways to prompt a LLM. While effective, they’re also very formulaic. To provide you with more freedom to express your prompts and still have them be good, I’ll then briefly discuss what I believe makes a good prompt.</p>
<p>The following are three popular prompt forms frequently cited by those with expertise in prompt engineering:</p>
<ul class="simple">
<li><p><strong>Instruction:</strong> This form begins with a command to the model that instructs it to do a particular task, and has you follow the command with your supporting data or context. For example, your prompt might begin with the statement: “Summarize the following text in a paragraph.” You’d follow this statement with the text to summarize.</p></li>
<li><p><strong>Completion:</strong> This form begins with the context you want the model to absorb and ends an incomplete statement that the model naturally tries to complete. Continuing with the example I used in the instruction form, you could start your prompt with the text you’d like summarized and then end with the incomplete sentence: “Briefly, this text discusses”.</p></li>
<li><p><strong>Demonstration:</strong> This form has you show the model what you want it to do through one or more examples and end with the question you want answered. It is reminiscence of supervised learning, and it is frequently called <em>few-shot learning</em>.</p></li>
</ul>
<p>As an example of a completion prompt, let’s continue to try to get ChatGPT to grab the actor names from a line of the form: <code class="docutils literal notranslate"><span class="pre">ACTOR1</span> <span class="pre">and</span> <span class="pre">ACTOR2</span> <span class="pre">starred</span> <span class="pre">in</span> <span class="pre">MOVIE</span></code>.</p>
<blockquote>
<div><p><strong>Me:</strong></p>
<p>Input: Carey Mulligan and Joel Edgerton starred in The Great Gatsby</p>
<p>Output: Carey Mulligan; Joel Edgerton</p>
<p>Input: Joel Edgerton and Hanna Mangan Lawrence starred in Acolytes</p>
<p>Output: Joel Edgerton; Hanna Mangan Lawrence</p>
<p>Input: Jane Tsentas and Cleo O’Hara starred in Evil Come Evil Go</p>
<p>Output: Jane Tsentas; Cleo O’Hara</p>
<p>Input: Aden Young and Marshall Napier starred in Shotgun Wedding</p>
<p>Output:</p>
<p><strong>ChatGPT:</strong> Aden Young; Marshall Napier</p>
</div></blockquote>
<p>It worked well, and to have ChatGPT generate code I could use to do this work, I can follow this demonstration prompt with an instruction prompt: “Please write me a Python function that does this work.” When I did this, ChatGPT produced the following function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1">### chap18/extract_actors.py -- Written by ChatGPT</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">re</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="k">def</span> <span class="nf">extract_actors</span><span class="p">(</span><span class="n">input_string</span><span class="p">):</span>
<span class="linenos"> 5</span>    <span class="c1"># Regular expression to match actor names</span>
<span class="linenos"> 6</span>    <span class="n">actor_pattern</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;([A-Z][a-z]+(?: [A-Z][a-z]+)+)&#39;</span><span class="p">)</span>
<span class="linenos"> 7</span>    
<span class="linenos"> 8</span>    <span class="c1"># Find all matches</span>
<span class="linenos"> 9</span>    <span class="n">actors</span> <span class="o">=</span> <span class="n">actor_pattern</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">input_string</span><span class="p">)</span>
<span class="linenos">10</span>    
<span class="linenos">11</span>    <span class="c1"># Join the actors with a semicolon</span>
<span class="linenos">12</span>    <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">actors</span><span class="p">)</span>
<span class="linenos">13</span>    
<span class="linenos">14</span>    <span class="k">return</span> <span class="n">result</span>
<span class="linenos">15</span>
<span class="linenos">16</span><span class="c1"># Example usage (from ChatGPT)</span>
<span class="linenos">17</span><span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Aden Young and Marshall Napier starred in Shotgun Wedding&quot;</span>
<span class="linenos">18</span><span class="nb">print</span><span class="p">(</span><span class="n">extract_actors</span><span class="p">(</span><span class="n">input_text</span><span class="p">))</span>
<span class="linenos">19</span>
<span class="linenos">20</span><span class="c1"># Another test of the code that I added</span>
<span class="linenos">21</span><span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;Jane Tsentas and Cleo O&#39;Hara starred in Evil Come Evil Go&quot;</span>
<span class="linenos">22</span><span class="nb">print</span><span class="p">(</span><span class="n">extract_actors</span><span class="p">(</span><span class="n">input_text</span><span class="p">))</span>
</pre></div>
</div>
<p>As typical, ChatGPT included an example that shows you how to invoke the function. I added another test. When you run <code class="docutils literal notranslate"><span class="pre">extract_actors.py</span></code>, you’ll find that ChatGPT’s test works fine, but the one I added doesn’t. And if you inspect the regular expression in <code class="docutils literal notranslate"><span class="pre">extract_actors</span></code>, you’ll see that it won’t work for names like “Cleo O’Hara”, which contain characters other than the letters <code class="docutils literal notranslate"><span class="pre">a-z</span></code>. This happened despite the fact that I included that name in my completion-prompt examples.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Even with good prompts, the solution produced with a GAI tool today won’t necessary work in all the situations you care about. Problem solving involves iteration, even when you use GAI.</p>
</div>
<p>You can find lots of websites on the internet that discuss prompt engineering. I view most of their advice as that which is appropriate for getting better outputs from a human assistant as well as a GAI tool. Here are some basic rules of thumb:</p>
<ul class="simple">
<li><p>When giving instructions, make them clear, detailed, and easy to find.</p>
<ul>
<li><p>If you want a comma-separated list, ask the tool to “return a comma-separated list.”</p></li>
<li><p>If you want the tool to say “I don’t know” when it doesn’t know the answer, tell it: Say “I don’t know” if you do not know the answer.</p></li>
<li><p>Put these explicit instructions at the start or end of your prompt (i.e., not buried somewhere in it).</p></li>
</ul>
</li>
<li><p>When a context for the model’s answer matters, state it.</p>
<ul>
<li><p>If you want a high-quality and detailed answer, tell the tool to answer as if it was an expert.</p></li>
<li><p>If you want an answer appropriate for a middle-school student, say that.</p></li>
</ul>
</li>
<li><p>When supplying examples, make them high-quality and diverse. If you cover the edge cases, it is more likely that the GAI tool will too.</p></li>
<li><p>When the model seems to struggle with your task, try telling it to “think step by step.” No one knows why this seems to help, but it appears to nudge a GAI tool to decompose the main task into subtasks, and this decomposition seems to improve its reasoning.</p></li>
</ul>
</section>
<section id="final-thoughts">
<p><strong>Final thoughts.</strong> GAI is a tool for problem solving. Learn for yourself what it is good at doing and where are its limitations. Like computers, they are flexible tools. Read and think critically about what others have successfully done with GAI, and then experiment with it on problems that matter to you.</p>
<p>Your goal is to use it for tasks within the GAI tool’s frontier. Chosen appropriately, these GAI-assisted tasks will make you, like the consultants in the HBS study, more productive in producing high-quality outputs, especially in those areas where your skills could use a boost.</p>
<p>But be vigilantly skeptical. Always check and never blindly accept a GAI tool’s output.</p>
<p>When all is said and done, problem solving with GAI is still the same process I described in Chapter 1. Whether you use Python or English to “program” the machine to solve your problem, your instructions need to be precise and carefully constructed.</p>
<p>Happy problem solving!</p>
<p>[Version 20241012]</p>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="fn1" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>The figure and findings discussed in this section are from Dell’Acqua, Fabrizio and McFowland III, Edward and Mollick, Ethan R. and Lifshitz-Assaf, Hila and Kellogg, Katherine and Rajendran, Saran and Krayer, Lisa and Candelon, François and Lakhani, Karim R., “Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality” (September 15, 2023). Harvard Business School Technology &amp; Operations Mgt. Unit Working Paper No. 24-013. The full text is available at SSRN (<a class="reference external" href="https://ssrn.com/abstract=4573321">https://ssrn.com/abstract=4573321</a>) or <a class="reference external" href="http://doi.org">doi.org</a> (<a class="reference external" href="http://dx.doi.org/10.2139/ssrn.4573321">http://dx.doi.org/10.2139/ssrn.4573321</a>).</p>
</aside>
<aside class="footnote brackets" id="fn2" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>If you want an excellent and understandable introduction to LLMs, I highly recommend <a class="reference external" href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">Stephen Wolfram’s “What Is ChatGPT Doing … and Why Does It Work?,” Stephen Wolfram Writings (2023)</a>. This section borrows from Wolfram’s lengthy article.</p>
</aside>
<aside class="footnote brackets" id="fn3" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>I say roughly because LLMs technically produce a <em>token</em>, which may not be a complete word and may be a punctuation mark. But to understand how LLMs work, we can simply think of these tokens as words.</p>
</aside>
<aside class="footnote brackets" id="fn4" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p>In some LLMs, you can adjust the model’s <em>temperature</em> setting to more strongly nudge it toward less likely words. But nudging it too far down its ranking will make the LLM sound like a lunatic. There’s that just-right nature of ML rising up again.</p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="chap17.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 17: Build Prediction Models</p>
      </div>
    </a>
    <a class="right-next"
       href="ales.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Active-Learning Exercises</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#navigating-the-jagged-frontier">Navigating the jagged frontier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#my-use-of-gai">My use of GAI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-llms">Large Language Models (LLMs)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-operation-of-llms">The operation of LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#complexity-from-simplicity">Complexity from simplicity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-neural-network">Training a neural network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#two-pieces-to-problem-solving-with-gai">Two pieces to problem solving with GAI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-easy-request">An easy request?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#write-the-script-ourselves">Write the script ourselves</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ask-chatgpt">Ask ChatGPT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-this-task-within-the-frontier">Is this task within the frontier?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-expanding-frontier">The expanding frontier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-problem-solve-with-a-llm">How to problem solve with a LLM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#writing-good-prompts">Writing good prompts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-thoughts">Final thoughts</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mike Smith
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023 by Michael D. Smith. All rights reserved.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>